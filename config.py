"""
å°è¯´ç”Ÿæˆå™¨é…ç½®æ–‡ä»¶

æ”¯æŒä¸¤ç§éƒ¨ç½²æ–¹å¼:
1. Gradio å‰ç«¯ + transformers ç›´æ¥åŠ è½½ AWQ æ¨¡å‹ (æ¨è)
2. Streamlit å‰ç«¯ + vLLM æœåŠ¡å™¨

ä½¿ç”¨æ–¹å¼1 (Gradio + AWQ):
    python gradio_app.py --model_path ./models/DeepSeek-R1-7B-AWQ --auto_load

ä½¿ç”¨æ–¹å¼2 (Streamlit + vLLM):
    python start_vllm_server.py --model ./models/DeepSeek-R1-7B-AWQ
    python -m streamlit run app.py
"""
import os
from pathlib import Path

# ==================== æ¨¡å‹é…ç½® ====================
# æ¨èçš„ DeepSeek-R1 è’¸é¦ç‰ˆæ¨¡å‹:
# - deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B (æœ€å°,æµ‹è¯•ç”¨, ~3GB æ˜¾å­˜)
# - deepseek-ai/DeepSeek-R1-Distill-Qwen-7B (é€‚åˆå•å¡, ~14GB æ˜¾å­˜)
# - deepseek-ai/DeepSeek-R1-Distill-Qwen-14B (éœ€è¦è¾ƒå¤§æ˜¾å­˜, ~28GB)
# - deepseek-ai/DeepSeek-R1-Distill-Qwen-32B (éœ€è¦å¤šå¡æˆ–å¤§æ˜¾å­˜)
# - deepseek-ai/DeepSeek-R1-Distill-Llama-70B (æ¥è¿‘72Bè§„æ¨¡)
#
# AWQ é‡åŒ–åæ˜¾å­˜éœ€æ±‚çº¦ä¸ºåŸå§‹æ¨¡å‹çš„ 1/4

# åŸå§‹æ¨¡å‹åç§°/è·¯å¾„ (ç”¨äºä¸‹è½½æˆ–é‡åŒ–)
MODEL_NAME = os.getenv("MODEL_NAME", "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B")

# AWQ é‡åŒ–æ¨¡å‹è·¯å¾„ (ç”¨äºéƒ¨ç½²)
AWQ_MODEL_PATH = os.getenv("AWQ_MODEL_PATH", "./models/DeepSeek-R1-7B-AWQ")

# æ¨¡å‹ç¼“å­˜ç›®å½•
MODEL_CACHE_DIR = os.getenv("MODEL_CACHE_DIR", "./models")

# ==================== Gradio é…ç½® (æ–¹å¼1) ====================
GRADIO_HOST = os.getenv("GRADIO_HOST", "0.0.0.0")
GRADIO_PORT = int(os.getenv("GRADIO_PORT", "7860"))
GRADIO_SHARE = os.getenv("GRADIO_SHARE", "false").lower() == "true"

# ==================== vLLM æœåŠ¡é…ç½® (æ–¹å¼2) ====================
VLLM_HOST = os.getenv("VLLM_HOST", "0.0.0.0")
VLLM_PORT = int(os.getenv("VLLM_PORT", "8000"))

# GPU é…ç½®
TENSOR_PARALLEL_SIZE = int(os.getenv("TENSOR_PARALLEL_SIZE", "1"))  # GPU æ•°é‡
GPU_MEMORY_UTILIZATION = float(os.getenv("GPU_MEMORY_UTILIZATION", "0.9"))

# ==================== ç”Ÿæˆå‚æ•°é…ç½® ====================
DEFAULT_MAX_TOKENS = 2048
DEFAULT_TEMPERATURE = 0.8
DEFAULT_TOP_P = 0.95
DEFAULT_TOP_K = 50
DEFAULT_REPETITION_PENALTY = 1.1

# ==================== AWQ é‡åŒ–é…ç½® ====================
AWQ_CONFIG = {
    "w_bit": 4,              # é‡åŒ–ä½å®½
    "q_group_size": 128,     # åˆ†ç»„å¤§å°
    "zero_point": True,      # é›¶ç‚¹é‡åŒ–
    "version": "GEMM",       # é‡åŒ–ç‰ˆæœ¬
}

# æ ¡å‡†æ•°æ®é›†é€‰é¡¹
CALIBRATION_DATASETS = [
    "pileval",      # é»˜è®¤ï¼Œé€‚åˆå¤§å¤šæ•°åœºæ™¯
    "wikitext",     # ç»´åŸºç™¾ç§‘æ–‡æœ¬
    "c4",           # Common Crawl
]

# ==================== å†å²è®°å½•é…ç½® ====================
PROJECT_ROOT = Path(__file__).parent
HISTORY_DIR = PROJECT_ROOT / "chat_history"
HISTORY_DIR.mkdir(exist_ok=True)

# ==================== Streamlit é…ç½® ====================
STREAMLIT_PORT = int(os.getenv("STREAMLIT_PORT", "8501"))

# ==================== å°è¯´åˆ›ä½œæç¤ºè¯ ====================
NOVEL_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½æ‰åæ¨ªæº¢çš„å°è¯´ä½œå®¶ï¼Œæ“…é•¿åˆ›ä½œå¼•äººå…¥èƒœçš„æ•…äº‹ã€‚ä½ çš„å†™ä½œç‰¹ç‚¹ï¼š

1. **æ–‡ç¬”ä¼˜ç¾**: å–„äºè¿ç”¨ä¿®è¾æ‰‹æ³•ï¼Œæ–‡å­—å¯Œæœ‰è¯—æ„å’Œç”»é¢æ„Ÿ
2. **æƒ…èŠ‚ç´§å‡‘**: æ•…äº‹å‘å±•æœ‰å¼ æœ‰å¼›ï¼Œæƒ…èŠ‚è·Œå®•èµ·ä¼
3. **äººç‰©é²œæ˜**: è§’è‰²æ€§æ ¼ç«‹ä½“ï¼Œå¯¹è¯ç”ŸåŠ¨è‡ªç„¶
4. **ç»†èŠ‚ä¸°å¯Œ**: åœºæ™¯æå†™ç»†è…»ï¼Œèƒ½è®©è¯»è€…èº«ä¸´å…¶å¢ƒ
5. **è¿è´¯æ€§å¼º**: èƒ½å¤Ÿæ ¹æ®ä¹‹å‰çš„æƒ…èŠ‚è‡ªç„¶å»¶ç»­æ•…äº‹å‘å±•

è¯·æ ¹æ®ç”¨æˆ·çš„è¦æ±‚è¿›è¡Œå°è¯´åˆ›ä½œã€‚åœ¨ç»­å†™æ—¶ï¼Œè¦ä¿æŒä¸ä¹‹å‰å†…å®¹çš„é£æ ¼ä¸€è‡´å’Œæƒ…èŠ‚è¿è´¯ã€‚
è¾“å‡ºæ ¼å¼è¦æ±‚ï¼šç›´æ¥è¾“å‡ºå°è¯´å†…å®¹ï¼Œä¸è¦ä½¿ç”¨markdownæ ¼å¼ï¼Œä¸è¦æ·»åŠ é¢å¤–çš„è§£é‡Šã€‚"""


# ==================== å¿«æ·å‡½æ•° ====================
def get_model_path(use_awq: bool = True) -> str:
    """è·å–æ¨¡å‹è·¯å¾„"""
    if use_awq:
        return AWQ_MODEL_PATH
    return MODEL_NAME


def print_config():
    """æ‰“å°å½“å‰é…ç½®"""
    print("="*60)
    print("ğŸ“‹ å½“å‰é…ç½®")
    print("="*60)
    print(f"  åŸå§‹æ¨¡å‹: {MODEL_NAME}")
    print(f"  AWQæ¨¡å‹: {AWQ_MODEL_PATH}")
    print(f"  æ¨¡å‹ç¼“å­˜: {MODEL_CACHE_DIR}")
    print(f"  Gradio: {GRADIO_HOST}:{GRADIO_PORT}")
    print(f"  vLLM: {VLLM_HOST}:{VLLM_PORT}")
    print(f"  GPUæ•°é‡: {TENSOR_PARALLEL_SIZE}")
    print("="*60)
