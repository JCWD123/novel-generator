# ========================================
# vLLM 部署依赖 - 稳定组合 (2025.01)
# ========================================
# 环境矩阵:
# - CUDA Runtime: 12.1
# - Python: 3.10
# - PyTorch: 2.1.2 + cu121
# - vLLM: 0.3.3
# ========================================

# ----------------------------------------
# 核心依赖 (版本锁定)
# ----------------------------------------
torch==2.1.2
triton==2.1.0
vllm==0.3.3

# ----------------------------------------
# LangChain 对话管理
# ----------------------------------------
langchain>=0.1.0,<0.2.0
langchain-core>=0.1.0,<0.2.0
langchain-community>=0.0.20,<0.1.0
langchain-openai>=0.0.5,<0.1.0

# ----------------------------------------
# Streamlit 前端
# ----------------------------------------
streamlit>=1.30.0,<2.0.0

# ----------------------------------------
# 其他依赖
# ----------------------------------------
# transformers 与 torch 2.1.2 兼容版本，避免 pytree 注册报错
transformers==4.35.2
accelerate>=0.25.0
sentencepiece
protobuf>=3.20.0
"outlines>=0.0.35,<0.0.37"
requests>=2.31.0

# ----------------------------------------
# 可选: AWQ 量化支持
# ----------------------------------------
# autoawq>=0.2.0

