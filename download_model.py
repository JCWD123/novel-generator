#!/usr/bin/env python3
"""
æ¨¡å‹ä¸‹è½½è„šæœ¬ - å¼ºåˆ¶ä½¿ç”¨é•œåƒç«™åŠ é€Ÿ

ç”¨æ³•ï¼š
    # å…ˆç™»å½• HuggingFaceï¼ˆé¿å…é™æµï¼‰
    huggingface-cli login
    
    # ç„¶åä¸‹è½½
    python download_model.py --model 7b
    python download_model.py --model 1.5b
"""

import os
import subprocess
import sys
import time

# å¼ºåˆ¶ä½¿ç”¨é•œåƒç«™
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"

# æ£€æµ‹ hf_transfer
def _check_hf_transfer():
    try:
        import hf_transfer
        return True
    except ImportError:
        return False

if _check_hf_transfer():
    os.environ["HF_HUB_ENABLE_HF_TRANSFER"] = "1"
    print("âš¡ hf_transfer åŠ é€Ÿ: å·²å¯ç”¨")
else:
    os.environ["HF_HUB_ENABLE_HF_TRANSFER"] = "0"
    print("âš ï¸ hf_transfer æœªå®‰è£…ï¼Œä½¿ç”¨æ™®é€šä¸‹è½½")

# DeepSeek-R1 è’¸é¦ç‰ˆæ¨¡å‹åˆ—è¡¨
MODELS = {
    "1.5b": "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
    "7b": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
    "14b": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
    "32b": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
    "70b": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
}


def check_hf_login():
    """æ£€æŸ¥æ˜¯å¦å·²ç™»å½• HuggingFace"""
    token = os.environ.get("HF_TOKEN") or os.environ.get("HUGGING_FACE_HUB_TOKEN")
    if token:
        print(f"âœ… æ£€æµ‹åˆ° HF_TOKEN ç¯å¢ƒå˜é‡")
        return True
    
    # æ£€æŸ¥ token æ–‡ä»¶
    token_path = os.path.expanduser("~/.cache/huggingface/token")
    if os.path.exists(token_path):
        print(f"âœ… æ£€æµ‹åˆ°å·²ç™»å½• HuggingFace")
        return True
    
    return False


def download_with_retry(model_id: str, max_retries: int = 3) -> bool:
    """
    å¸¦é‡è¯•çš„ä¸‹è½½å‡½æ•°
    """
    for attempt in range(max_retries):
        print(f"\n{'='*60}")
        print(f"ğŸ“¥ ä¸‹è½½æ¨¡å‹: {model_id} (å°è¯• {attempt + 1}/{max_retries})")
        print(f"ğŸŒ é•œåƒç«™: {os.environ.get('HF_ENDPOINT')}")
        print(f"{'='*60}")
        
        # ä½¿ç”¨æ–°å‘½ä»¤ hf downloadï¼ˆé¿å… deprecated è­¦å‘Šï¼‰
        cmd = ["hf", "download", model_id]
        
        try:
            result = subprocess.run(cmd, check=True, capture_output=False)
            print(f"\nâœ… ä¸‹è½½å®Œæˆ: {model_id}")
            return True
        except FileNotFoundError:
            # hf å‘½ä»¤ä¸å­˜åœ¨ï¼Œå›é€€åˆ° huggingface-cli
            cmd = ["huggingface-cli", "download", model_id]
            try:
                subprocess.run(cmd, check=True)
                print(f"\nâœ… ä¸‹è½½å®Œæˆ: {model_id}")
                return True
            except subprocess.CalledProcessError as e:
                if "429" in str(e) or attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 30
                    print(f"\nâš ï¸ è¯·æ±‚è¢«é™æµï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                else:
                    return False
        except subprocess.CalledProcessError as e:
            if attempt < max_retries - 1:
                wait_time = (attempt + 1) * 30
                print(f"\nâš ï¸ ä¸‹è½½å¤±è´¥ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                time.sleep(wait_time)
            else:
                return False
    
    return False


def main():
    import argparse
    
    parser = argparse.ArgumentParser(
        description="ä¸‹è½½ DeepSeek-R1 æ¨¡å‹ï¼ˆé•œåƒç«™åŠ é€Ÿï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
æ¨¡å‹åˆ—è¡¨:
  1.5b  -> deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B  (~3GB)
  7b    -> deepseek-ai/DeepSeek-R1-Distill-Qwen-7B    (~14GB)
  14b   -> deepseek-ai/DeepSeek-R1-Distill-Qwen-14B   (~28GB)
  32b   -> deepseek-ai/DeepSeek-R1-Distill-Qwen-32B   (~64GB)
  70b   -> deepseek-ai/DeepSeek-R1-Distill-Llama-70B  (~140GB)

å¦‚æœé‡åˆ° 429 é™æµé”™è¯¯ï¼Œè¯·å…ˆç™»å½•:
  huggingface-cli login

æˆ–è®¾ç½® token:
  export HF_TOKEN="hf_xxxxxxxxxxxx"
        """
    )
    
    parser.add_argument("--model", "-m", type=str, choices=list(MODELS.keys()),
                        help="æ¨¡å‹åç§° (1.5b/7b/14b/32b/70b)")
    parser.add_argument("--model-id", type=str, help="å®Œæ•´ HuggingFace æ¨¡å‹ ID")
    parser.add_argument("--retry", type=int, default=3, help="é‡è¯•æ¬¡æ•° (é»˜è®¤: 3)")
    
    args = parser.parse_args()
    
    print(f"ğŸŒ ä½¿ç”¨é•œåƒç«™: {os.environ.get('HF_ENDPOINT')}")
    
    # æ£€æŸ¥ç™»å½•çŠ¶æ€
    if not check_hf_login():
        print("\nâš ï¸ æœªæ£€æµ‹åˆ° HuggingFace ç™»å½•")
        print("   å¦‚æœé‡åˆ° 429 é™æµé”™è¯¯ï¼Œè¯·å…ˆç™»å½•:")
        print("   huggingface-cli login")
        print("")
    
    # ç¡®å®šæ¨¡å‹ ID
    if args.model:
        model_id = MODELS[args.model]
    elif args.model_id:
        model_id = args.model_id
    else:
        parser.print_help()
        print("\nâŒ è¯·æŒ‡å®š --model æˆ– --model-id")
        sys.exit(1)
    
    # ä¸‹è½½
    success = download_with_retry(model_id, max_retries=args.retry)
    
    if success:
        print("\n" + "="*60)
        print("âœ… ä¸‹è½½å®Œæˆ!")
        print(f"ä¸‹ä¸€æ­¥: python start_vllm_server.py --model {args.model or model_id}")
        print("="*60)
    else:
        print("\n" + "="*60)
        print("âŒ ä¸‹è½½å¤±è´¥!")
        print("   å¯èƒ½çš„åŸå› :")
        print("   1. ç½‘ç»œé—®é¢˜")
        print("   2. é•œåƒç«™é™æµ (429)")
        print("")
        print("   è§£å†³æ–¹æ¡ˆ:")
        print("   1. huggingface-cli login  # ç™»å½•è·å– token")
        print("   2. ç¨åé‡è¯•")
        print("   3. å°è¯•å®˜æ–¹æº: export HF_ENDPOINT=https://huggingface.co")
        print("="*60)
        sys.exit(1)


if __name__ == "__main__":
    main()

